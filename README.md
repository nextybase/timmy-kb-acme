# Timmy-KB â€“ Knowledge Base Onboarding Pipeline (v1.0)

---

Pipeline modulare e automatizzata per lâ€™onboarding strutturato di PMI nella piattaforma NeXT, con generazione di knowledge base in Markdown semantico e pubblicazione continua su GitHub/GitBook.

## ğŸ§  Filosofia e Obiettivi

La pipeline Timmy-KB garantisce che ogni informazione, tag, relazione e categoria sia esplicitamente dichiarata e tracciabile, secondo policy e mapping YAML forniti a monte. Nessuna inferenza automatica viene applicata senza controllo: la semantica Ã¨ sempre dichiarata, non dedotta.

- Parsing e strutturazione deterministici e auditabili
- Semantica e relazioni forti, sempre definite da configurazione
- Ideale per generare database relazionali e knowledge graph affidabili

## ğŸ¯ Scopo

- Automatizzare onboarding documentale e operativo per organizzazioni in ecosistemi NeXT
- Generare una Knowledge Base semantica e normalizzata, pronta per le successive fasi AI
- Separare orchestrazione e semantica, mantenendo la pipeline come layer tecnico
- Centralizzare configurazione e logging per massimo controllo
- Supportare preview locale (Docker/Honkit), test end-to-end e deploy automatico

## ğŸ§© Architettura (overview)

- **Pipeline modulare**: separazione tra moduli tecnici (`src/pipeline/`), semantici (`src/semantic/`), e strumenti (`src/tools/`)
- **Orchestratori CLI-ready**: orchestratori root (`src/pre_onboarding.py`, `src/onboarding_full.py`) gestiscono tutto il flusso e sono utilizzabili sia in modalitÃ  manuale (con input guidato) che automatica (parametri CLI)
- **Configurazione centralizzata**: variabili dâ€™ambiente e YAML gestiti da moduli dedicati
- **Output knowledge base**: Markdown generati raccolti in `output/book/`, pronti per deploy
- **Logging strutturato**: ogni step loggato su file/console tramite logger dedicato

## ğŸ—ï¸ Struttura cartelle principale

```
project-root/
â”œâ”€â”€ output/
â”‚   â””â”€â”€ timmy-kb-<slug>/
â”‚       â”œâ”€â”€ raw/           # PDF originali da Drive
â”‚       â”œâ”€â”€ book/          # Markdown generati
â”‚       â””â”€â”€ config/        # File di configurazione cliente
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/          # Moduli tecnici
â”‚   â”œâ”€â”€ semantic/          # Funzioni semantiche
â”‚   â””â”€â”€ tools/             # Strumenti di supporto e dummy KB
â”œâ”€â”€ tests/                 # Test unitari ed E2E
â”œâ”€â”€ logs/                  # Log strutturati
â””â”€â”€ .env                   # Configurazione centralizzata
```

## âš™ï¸ Prerequisiti

- Python 3.10+
- Docker
- Account Google Drive + service account JSON
- Token GitHub con permessi repo
- Variabili configurate in `.env`

## ğŸš¦ Quickstart

1. **Clona il repository e installa le dipendenze**
2. \*\*Configura \*\*\`\` (vedi esempio nel repo)
3. **Esegui il pre-onboarding:**
   ```bash
   python src/pre_onboarding.py
   ```
   Segui i prompt per slug/nome cliente oppure usa i parametri CLI (`--slug`, `--client-name`, `--no-interactive`)
4. **Popola la cartella Drive** con i PDF richiesti
5. **Esegui onboarding completo:**
   ```bash
   python src/onboarding_full.py
   ```
   Usa i flag CLI per modalitÃ  automatica (`--slug`, `--auto-push`, `--skip-preview`, `--no-interactive`), oppure interagisci guidato

## ğŸ§ª Testing e Dummy Data

Tutti i dati di test sono generati tramite:

```bash
python src/tools/gen_dummy_kb.py
```

- Slug di test: sempre `dummy`
- Output test separato da dati reali (`output/timmy-kb-dummy/`)
- Tutti i test (`tests/`) sono idempotenti, batch/manuale friendly e automatizzati
- In modalitÃ  batch (`BATCH_TEST=1 pytest tests/`): nessun input richiesto, cleanup automatico

## ğŸ“¦ Funzioni principali e CLI orchestratori

Gli orchestratori supportano:

- `--slug`: slug del cliente
- `--client-name`: nome cliente (pre-onboarding)
- `--no-interactive`: disabilita input (solo batch/CI)
- `--auto-push`: push GitHub automatico senza conferma
- `--skip-preview`: salta preview Honkit/Docker

Tutti i parametri possono essere combinati per workflow automatici. In assenza, il tool guida lâ€™utente passo-passo.

## ğŸªµ Logging e Debug

- Log sempre su file in `logs/` e in console
- Debug e errori tracciati da logger strutturato, mai via print
- Ogni funzione tecnica/semantica deve loggare input/output/errore

## ğŸ“ Policy, regole e documentazione

- **Regole di coding**: [coding\_rule.md](coding_rule.md)
- **Manifesto tecnico**: [manifesto\_tecnico.md](manifesto_tecnico.md)
- **Best practice pipeline**: PDF â€œBest practices per pipeline Pythonâ€ (Kedro, Airflow, Luigi)
- **Modello NeXT**: Paper NeXT allegato

Consulta sempre questi file PRIMA di modificare la pipeline o aprire PR.

---

**Per bug/anomalie, apri issue su GitHub allegando log e dettagli.**

